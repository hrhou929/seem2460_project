{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"initial_id","cell_type":"code","source":"import time\n\nimport torch\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport torchvision\nimport torchvision.transforms\nimport matplotlib.pyplot as plt\nimport imgaug as ia\nimport imgaug.augmenters as iaa\n\n\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\n\n\nimport torch.nn\nfrom torch import nn\n# from torchvision.models import resnet50, ResNet50_Weights","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:27.040618Z","start_time":"2025-04-09T10:09:24.963213Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:07.575260Z","iopub.execute_input":"2025-04-10T08:53:07.575474Z","iopub.status.idle":"2025-04-10T08:53:38.144401Z","shell.execute_reply.started":"2025-04-10T08:53:07.575455Z","shell.execute_reply":"2025-04-10T08:53:38.143416Z"}},"outputs":[{"name":"stderr","text":"2025-04-10 08:53:25.245113: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744275205.475349      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744275205.536055      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"id":"7d23f94b59ae7125","cell_type":"code","source":"csv_path = \"/Users/hou/Desktop/seem2460/animal-clef-2025/metadata.csv\"\ndata_root = \"/Users/hou/Desktop/seem2460/animal-clef-2025\"\nquerying_class_paths = {\n    \"SeaTurtle_Query\": \"images/SeaTurtleID2022/query/images\",\n    \"Lynxs_Query\": \"images/LynxID2025/query\",\n    \"Salamanders_Query\": \"images/SalamanderID2025/query/images\"\n}\ntraining_class_paths = {\n    \"SeaTurtle_Data\": \"images/SeaTurtleID2022/database/turtles-data/data/images\",\n    \"Lynxs_Data\": \"images/LynxID2025/database\",\n    \"Salamanders_Data\": \"images/SalamanderID2025/database/images\"\n}","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:27.045606Z","start_time":"2025-04-09T10:09:27.043726Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.145499Z","iopub.execute_input":"2025-04-10T08:53:38.146080Z","iopub.status.idle":"2025-04-10T08:53:38.150813Z","shell.execute_reply.started":"2025-04-10T08:53:38.146053Z","shell.execute_reply":"2025-04-10T08:53:38.149869Z"}},"outputs":[],"execution_count":2},{"id":"68b913f708029e2d","cell_type":"code","source":"df = pd.read_csv(csv_path)\ndf.head()","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:27.121141Z","start_time":"2025-04-09T10:09:27.097413Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.152911Z","iopub.execute_input":"2025-04-10T08:53:38.153281Z","iopub.status.idle":"2025-04-10T08:53:38.450749Z","shell.execute_reply.started":"2025-04-10T08:53:38.153253Z","shell.execute_reply":"2025-04-10T08:53:38.449087Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/269028964.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/tingshuoliang/Downloads/CNN_test/animal-clef-2025/metadata.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/Users/tingshuoliang/Downloads/CNN_test/animal-clef-2025/metadata.csv'","output_type":"error"}],"execution_count":3},{"id":"a92a9c4aa2f11686","cell_type":"code","source":"class AnimalDataset(Dataset):\n    def __init__(self, csv_file, root_dir, class_paths, transform=None):\n        # external\n        self.data = csv_file\n        self.root_dir = root_dir\n        self.class_paths = class_paths\n        self.transform = transform\n\n        # internal\n        self.identities = self.data['identity'].unique()\n        self.identity_to_label = {identity: idx for idx, identity in enumerate(self.identities)}\n        \n        self.orientations = self.data['orientation'].unique()\n        self.orientation_to_label = {orientation: idx for idx, orientation in enumerate(self.orientations)}\n\n        self.filtered_data = []\n        for _, row in self.data.iterrows():\n            for class_name, class_path in class_paths.items():\n                if row['path'].startswith(class_path):\n                    self.filtered_data.append({\n                        'image_path': row['path'],\n                        'identity': row['identity'],\n                        'class': class_name,\n                        'orientation': row['orientation']\n                    })\n                    break\n\n    def __len__(self):\n        return len(self.filtered_data)\n\n    def __getitem__(self, idx):\n        img_info = self.filtered_data[idx]\n        img_path = os.path.join(self.root_dir, img_info['image_path'])\n\n        image = Image.open(img_path).convert('RGB')\n        identity_label = self.identity_to_label[img_info['identity']]\n        class_label = list(self.class_paths.keys()).index(img_info['class'])\n        orientation_label = self.orientation_to_label[img_info['orientation']]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, identity_label, class_label, orientation_label","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:27.146689Z","start_time":"2025-04-09T10:09:27.143132Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.451502Z","iopub.status.idle":"2025-04-10T08:53:38.451861Z","shell.execute_reply.started":"2025-04-10T08:53:38.451673Z","shell.execute_reply":"2025-04-10T08:53:38.451691Z"}},"outputs":[],"execution_count":null},{"id":"a41ac57a67aebf63","cell_type":"code","source":"Basic_Transform = transforms.Compose([\n    transforms.Resize([224, 224]),\n    transforms.ToTensor()\n])","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:27.172092Z","start_time":"2025-04-09T10:09:27.170239Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.453482Z","iopub.status.idle":"2025-04-10T08:53:38.453817Z","shell.execute_reply.started":"2025-04-10T08:53:38.453653Z","shell.execute_reply":"2025-04-10T08:53:38.453667Z"}},"outputs":[],"execution_count":null},{"id":"39fda507bd950bd5","cell_type":"code","source":"Training_dataset = AnimalDataset(csv_file=df, root_dir=data_root, class_paths=training_class_paths, transform=Basic_Transform)\nlen(Training_dataset)","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:27.449997Z","start_time":"2025-04-09T10:09:27.216927Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.454752Z","iopub.status.idle":"2025-04-10T08:53:38.455070Z","shell.execute_reply.started":"2025-04-10T08:53:38.454895Z","shell.execute_reply":"2025-04-10T08:53:38.454911Z"}},"outputs":[],"execution_count":null},{"id":"64ab90017703e511","cell_type":"code","source":"Querying_dataset = AnimalDataset(csv_file=df, root_dir=data_root, class_paths=querying_class_paths, transform=Basic_Transform)\nlen(Querying_dataset)","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:27.731808Z","start_time":"2025-04-09T10:09:27.519199Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.456241Z","iopub.status.idle":"2025-04-10T08:53:38.456570Z","shell.execute_reply.started":"2025-04-10T08:53:38.456382Z","shell.execute_reply":"2025-04-10T08:53:38.456397Z"}},"outputs":[],"execution_count":null},{"id":"3e866f994b5e22d1","cell_type":"code","source":"initLoader = DataLoader(Training_dataset, batch_size=64, shuffle=False, drop_last=False)","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:27.803867Z","start_time":"2025-04-09T10:09:27.802236Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.458041Z","iopub.status.idle":"2025-04-10T08:53:38.458402Z","shell.execute_reply.started":"2025-04-10T08:53:38.458226Z","shell.execute_reply":"2025-04-10T08:53:38.458243Z"}},"outputs":[],"execution_count":null},{"id":"bc0aa40cea83825c","cell_type":"code","source":"# writer = SummaryWriter(log_dir='ori_que_pics')\n# step = 0\n# for data in initLoader:\n#     image, identity_label, class_label, orientation_label = data\n#     writer.add_images(\"image\", image, step)\n#     print(f\"Step {step} written successfully.\")\n#     step += 1\n#     \n# writer.close()","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:27.813305Z","start_time":"2025-04-09T10:09:27.811553Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.459041Z","iopub.status.idle":"2025-04-10T08:53:38.459347Z","shell.execute_reply.started":"2025-04-10T08:53:38.459228Z","shell.execute_reply":"2025-04-10T08:53:38.459239Z"}},"outputs":[],"execution_count":null},{"id":"95b7af24b8b57b46","cell_type":"code","source":"def firstBatchSamplePlot(theDataloader, theDataset):\n    # only the first batch for display\n    for data in theDataloader:\n        images, identity_labels, _, orientation_labels = data\n        break\n        \n    # reverse dic\n    label_to_identity = {v: k for k, v in theDataset.identity_to_label.items()}\n    label_to_orientation = {v: k for k, v in theDataset.orientation_to_label.items()}\n    \n    images = images.numpy()\n    \n    fig = plt.figure(figsize=(20, 20))\n    rows, cols = 8, 8\n    \n    for i in range(min(64, len(images))):\n        ax = fig.add_subplot(rows, cols, i+1)\n    \n        # if CHW to HWC\n        if images.shape[1] == 1 or images.shape[1] == 3:\n            img = np.transpose(images[i], (1, 2, 0))\n        else:\n            img = images[i]\n    \n        identity = label_to_identity[identity_labels[i].item()]\n        orientation = label_to_orientation[orientation_labels[i].item()]\n    \n    \n        ax.imshow(img)\n        ax.set_title(f\"ID: {identity}\\nOri: {orientation}\", fontsize=8)\n        ax.axis('off')","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:27.829931Z","start_time":"2025-04-09T10:09:27.821559Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.460030Z","iopub.status.idle":"2025-04-10T08:53:38.460348Z","shell.execute_reply.started":"2025-04-10T08:53:38.460233Z","shell.execute_reply":"2025-04-10T08:53:38.460245Z"}},"outputs":[],"execution_count":null},{"id":"61eecd4a3a28ecfc","cell_type":"code","source":"firstBatchSamplePlot(initLoader, Training_dataset)","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:29.648143Z","start_time":"2025-04-09T10:09:27.842270Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.461527Z","iopub.status.idle":"2025-04-10T08:53:38.461893Z","shell.execute_reply.started":"2025-04-10T08:53:38.461718Z","shell.execute_reply":"2025-04-10T08:53:38.461735Z"}},"outputs":[],"execution_count":null},{"id":"8d7b31e2043c45f4","cell_type":"code","source":"# provided by imgaug document\nbasicAug = iaa.Sequential([\n    iaa.Fliplr(0.5), # horizontal flips\n    iaa.Crop(percent=(0, 0.1)), # random crops\n    # Small gaussian blur with random sigma between 0 and 0.5.\n    # But we only blur about 50% of all images.\n    iaa.Sometimes(\n        0.5,\n        iaa.GaussianBlur(sigma=(0, 0.5))\n    ),\n    # Strengthen or weaken the contrast in each image.\n    iaa.LinearContrast((0.75, 1.5)),\n    # Add gaussian noise.\n    # For 50% of all images, we sample the noise once per pixel.\n    # For the other 50% of all images, we sample the noise per pixel AND\n    # channel. This can change the color (not only brightness) of the\n    # pixels.\n    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n    # Make some images brighter and some darker.\n    # In 20% of all cases, we sample the multiplier once per channel,\n    # which can end up changing the color of the images.\n    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n    # Apply affine transformations to each image.\n    # Scale/zoom them, translate/move them, rotate them and shear them.\n    iaa.Affine(\n        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n        rotate=(-25, 25),\n        shear=(-8, 8)\n    )\n], random_order=True) # apply augmenters in random order","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:29.661434Z","start_time":"2025-04-09T10:09:29.657437Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.463006Z","iopub.status.idle":"2025-04-10T08:53:38.463916Z","shell.execute_reply.started":"2025-04-10T08:53:38.463773Z","shell.execute_reply":"2025-04-10T08:53:38.463790Z"}},"outputs":[],"execution_count":null},{"id":"f7df6e6b10230ab9","cell_type":"code","source":"EgAug = iaa.Sequential([\n    # 水平翻转\n    iaa.Fliplr(0.5),\n    \n    # 裁剪\n    iaa.Crop(percent=(0.1, 0.3)),\n    \n    # 颜色\n    iaa.MultiplySaturation((0.3, 2.0)),\n    \n    # 对比度\n    iaa.LinearContrast((0.4, 2.0)),\n    \n    # 亮度\n    iaa.Multiply((0.6, 1.4)),\n    \n    # 噪声\n    iaa.AdditiveGaussianNoise(scale=(0.1*255, 0.2*255)),\n    \n    # 模糊效果\n    iaa.GaussianBlur(sigma=(1.0, 3.0)),\n    \n    # 几何变换\n    iaa.Affine(\n        scale={\"x\": (0.7, 1.3), \"y\": (0.7, 1.3)},\n        translate_percent={\"x\": (-0.3, 0.3), \"y\": (-0.3, 0.3)},\n        rotate=(-45, 45),\n        shear=(-16, 16)\n    ),\n    \n    # 透视变换\n    iaa.PerspectiveTransform(scale=(0.1, 0.2))\n], random_order=True)\n","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:29.670685Z","start_time":"2025-04-09T10:09:29.666935Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.464994Z","iopub.status.idle":"2025-04-10T08:53:38.465290Z","shell.execute_reply.started":"2025-04-10T08:53:38.465140Z","shell.execute_reply":"2025-04-10T08:53:38.465155Z"}},"outputs":[],"execution_count":null},{"id":"c87c82b5a5a3c125","cell_type":"code","source":"augmentation_seq = iaa.Sequential([\n    iaa.Sometimes(0.7, iaa.MultiplyBrightness((0.8, 1.3))),\n    iaa.Sometimes(0.3, iaa.GammaContrast((0.7, 1.5))),\n    iaa.Sometimes(0.8, iaa.CLAHE(clip_limit=(1, 6), tile_grid_size_px=(8, 8))),\n    \n    iaa.Sometimes(0.3, iaa.AddToHueAndSaturation((-13, 13))),\n    iaa.Sometimes(0.6,\n        iaa.WithColorspace(\n            to_colorspace=\"HSV\",\n            from_colorspace=\"RGB\",\n            children=iaa.WithChannels(\n                0,\n                iaa.Add((-10, 10))\n            )\n        )\n    ),\n    \n    iaa.Sometimes(0.6,iaa.AdditivePoissonNoise(lam=(0, 5))),\n    \n    iaa.Sometimes(0.3,\n        iaa.Affine(\n            translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n            mode='constant',\n            cval=0\n        )\n    ),\n    iaa.Sometimes(0.4,\n        iaa.Affine(\n            rotate=(-30, 30),\n            mode='constant',\n            cval=0\n        )\n    ),\n    iaa.Sometimes(0.6,\n        iaa.Affine(\n            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n            mode='constant',\n            cval=0\n        )\n    ),\n    \n    iaa.Sometimes(0.1,iaa.GaussianBlur(sigma=(0.0, 1.0))),\n    iaa.Sometimes(0.3,iaa.Sharpen(alpha=(0.0, 0.5), lightness=(0.6, 1.4)))\n], random_order=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.466485Z","iopub.status.idle":"2025-04-10T08:53:38.466798Z","shell.execute_reply.started":"2025-04-10T08:53:38.466671Z","shell.execute_reply":"2025-04-10T08:53:38.466686Z"}},"outputs":[],"execution_count":null},{"id":"d79b633b49e13812","cell_type":"code","source":"class AugmentedDataset(Dataset):\n    def __init__(self, original_dataset, augmentation):\n        self.original_dataset = original_dataset\n        self.augmentation = augmentation\n        self.augmented_images = []\n        self.identity_labels = []\n        self.orientation_labels = []\n        self.class_labels = []\n        \n        loader = DataLoader(original_dataset, batch_size=64, shuffle=False, drop_last=False)\n        \n        progress_bar = tqdm(loader, desc=\"Processing\", unit=\"batch\")\n        \n        for images, identity_labels, class_label, orientation_labels in progress_bar:\n\n            if images.is_cuda:\n                images = images.cpu()\n            \n            images_np = images.numpy()\n            # CHW HWC\n            images_np = np.transpose(images_np, (0, 2, 3, 1))\n            # if 0-1, back to 0-255\n            if images_np.max() <= 1.0:\n                images_np = (images_np * 255).astype(np.uint8)\n            \n            images_aug = self.augmentation(images=images_np)\n            \n            for i in range(len(images_aug)):\n                img_aug = np.transpose(images_aug[i], (2, 0, 1)).astype(np.float32) / 255.0\n                self.augmented_images.append(img_aug)\n                self.identity_labels.append(identity_labels[i].item())\n                self.orientation_labels.append(orientation_labels[i].item())\n                self.class_labels.append(class_label[i].item())\n    \n    def __len__(self):\n        return len(self.augmented_images)\n    \n    def __getitem__(self, idx):\n        return (torch.tensor(self.augmented_images[idx]), \n                self.identity_labels[idx], \n                self.class_labels[idx],\n                self.orientation_labels[idx])\n","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:29.680691Z","start_time":"2025-04-09T10:09:29.676636Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.468157Z","iopub.status.idle":"2025-04-10T08:53:38.468419Z","shell.execute_reply.started":"2025-04-10T08:53:38.468299Z","shell.execute_reply":"2025-04-10T08:53:38.468310Z"}},"outputs":[],"execution_count":null},{"id":"96b1e6de123e5db1","cell_type":"code","source":"augmented_dataset = AugmentedDataset(Training_dataset, basicAug)\naugDataloader = DataLoader(augmented_dataset, batch_size=64, shuffle=False, drop_last=False)","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:34.581076Z","start_time":"2025-04-09T10:09:29.687292Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.469387Z","iopub.status.idle":"2025-04-10T08:53:38.469695Z","shell.execute_reply.started":"2025-04-10T08:53:38.469515Z","shell.execute_reply":"2025-04-10T08:53:38.469529Z"}},"outputs":[],"execution_count":null},{"id":"a8cf42cce946e06b","cell_type":"code","source":"firstBatchSamplePlot(augDataloader, Training_dataset)","metadata":{"ExecuteTime":{"end_time":"2025-04-09T10:09:34.647422Z","start_time":"2025-04-09T10:07:40.245371Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:53:38.470641Z","iopub.status.idle":"2025-04-10T08:53:38.470915Z","shell.execute_reply.started":"2025-04-10T08:53:38.470795Z","shell.execute_reply":"2025-04-10T08:53:38.470805Z"}},"outputs":[],"execution_count":null}]}